{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8XT/PttkPSd920CMlg29E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51lb8/Sai-Ganesh-NLP/blob/main/NLP_LAB_ASSIGNMENT_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load data fromkeras.datasets and perform following computational analysis:\n",
        "(a) Preprocessing of the Data\n",
        "\n",
        "(b) Divide data into training and testing data set\n",
        "\n",
        "(c) Build the Gated Recurrent Units (GRU) Model\n",
        "\n",
        "(d) Training the GRU Model\n",
        "\n",
        "(e) Text Generation Using the Trained Model\n",
        "\n",
        "(f) Evaluate Model’s accuracy"
      ],
      "metadata": {
        "id": "JNRLKqTY1iFY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zX7f4NPP11WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "# 1. Load IMDB dataset\n",
        "max_features = 10000  # Only consider the top 10k words\n",
        "max_len = 200\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "\n",
        "# (a) Preprocessing of the Data\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# (b) Divide data into training and testing data set\n",
        "# Already done in the previous code\n",
        "\n",
        "# (c) Build the GRU Model\n",
        "def build_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "    model.add(GRU(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# (d) Training the GRU Model\n",
        "gru_model = build_gru_model()\n",
        "print(\"Training GRU model...\")\n",
        "gru_history = gru_model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)\n",
        "\n",
        "\n",
        "# (e) Text Generation Using the Trained Model\n",
        "seed_text = x_test[0]\n",
        "prediction = gru_model.predict(np.array([seed_text]))\n",
        "sentiment = \"positive\" if prediction > 0.5 else \"negative\"\n",
        "print(f\"Predicted sentiment for the input sequence: {sentiment}\")\n",
        "\n",
        "\n",
        "# (f) Evaluate Model’s Accuracy\n",
        "gru_test_loss, gru_test_acc = gru_model.evaluate(x_test, y_test)\n",
        "print(f\"GRU Test Accuracy: {gru_test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14893d8-1359-4249-95f4-60a79c0698a4",
        "id": "LoQue3Ep126U"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GRU model...\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 491ms/step - accuracy: 0.6468 - loss: 0.6197 - val_accuracy: 0.8384 - val_loss: 0.3802\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 484ms/step - accuracy: 0.8878 - loss: 0.2744 - val_accuracy: 0.8716 - val_loss: 0.3251\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 495ms/step - accuracy: 0.9337 - loss: 0.1757 - val_accuracy: 0.8614 - val_loss: 0.3383\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 489ms/step - accuracy: 0.9621 - loss: 0.1044 - val_accuracy: 0.8694 - val_loss: 0.3617\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 494ms/step - accuracy: 0.9835 - loss: 0.0533 - val_accuracy: 0.8628 - val_loss: 0.5415\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "Predicted sentiment for the input sequence: negative\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - accuracy: 0.8532 - loss: 0.5900\n",
            "GRU Test Accuracy: 0.8538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets."
      ],
      "metadata": {
        "id": "K6qdZa5txL0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44VREq1RoX0E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load IMDB dataset\n",
        "max_features = 10000  # Only consider the top 10k words\n",
        "max_len = 200  # Cut off texts after this number of words (for padding)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2QzG3-wrKKL",
        "outputId": "bd3d0a4c-8fa8-47f6-cf76-5d4814c76a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to ensure all inputs are of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "W7kuksGlrZo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an LSTM model\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "    model.add(LSTM(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "z0j2sBuCsCzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a GRU model\n",
        "def build_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "    model.add(GRU(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "vbAjA399sHv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the LSTM model\n",
        "lstm_model = build_lstm_model()\n",
        "print(\"Training LSTM model...\")\n",
        "lstm_history = lstm_model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSjiSrGasdjg",
        "outputId": "22d4aec5-2298-467b-fcde-dc411d6c5940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 572ms/step - accuracy: 0.6822 - loss: 0.5633 - val_accuracy: 0.8640 - val_loss: 0.3250\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 566ms/step - accuracy: 0.8987 - loss: 0.2583 - val_accuracy: 0.8782 - val_loss: 0.3083\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 595ms/step - accuracy: 0.9364 - loss: 0.1737 - val_accuracy: 0.8608 - val_loss: 0.3338\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 573ms/step - accuracy: 0.9543 - loss: 0.1290 - val_accuracy: 0.8508 - val_loss: 0.3823\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 576ms/step - accuracy: 0.9614 - loss: 0.1173 - val_accuracy: 0.8464 - val_loss: 0.4080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the GRU model\n",
        "gru_model = build_gru_model()\n",
        "print(\"Training GRU model...\")\n",
        "gru_history = gru_model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cBxPvr8xWez",
        "outputId": "98474c6d-ee85-4d39-bf97-c16a106b8ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GRU model...\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 611ms/step - accuracy: 0.6533 - loss: 0.5998 - val_accuracy: 0.8398 - val_loss: 0.3667\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 618ms/step - accuracy: 0.8784 - loss: 0.3017 - val_accuracy: 0.8182 - val_loss: 0.4089\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 610ms/step - accuracy: 0.9104 - loss: 0.2343 - val_accuracy: 0.8540 - val_loss: 0.3722\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 609ms/step - accuracy: 0.9536 - loss: 0.1321 - val_accuracy: 0.8650 - val_loss: 0.3571\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 606ms/step - accuracy: 0.9698 - loss: 0.0921 - val_accuracy: 0.8450 - val_loss: 0.4546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate both models on the test set\n",
        "lstm_test_loss, lstm_test_acc = lstm_model.evaluate(x_test, y_test)\n",
        "gru_test_loss, gru_test_acc = gru_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print the comparison\n",
        "print(f\"\\nLSTM Test Accuracy: {lstm_test_acc:.4f}\")\n",
        "print(f\"GRU Test Accuracy: {gru_test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqDwzExf1Pxp",
        "outputId": "31cc892c-6fe4-483f-d1aa-198ddb7acce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 124ms/step - accuracy: 0.8424 - loss: 0.4302\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 68ms/step - accuracy: 0.8446 - loss: 0.4777\n",
            "\n",
            "LSTM Test Accuracy: 0.8449\n",
            "GRU Test Accuracy: 0.8448\n"
          ]
        }
      ]
    }
  ]
}